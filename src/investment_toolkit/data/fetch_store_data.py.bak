import requests
import json
from src.utilities.config import FMP_API_KEY_PRIMARY as API_KEY  # APIキーをインポート
import os
import pandas as pd
from datetime import datetime, timedelta, timezone
import logging
from sqlalchemy import create_engine, text
from src.utilities.config import DB_USER, DB_PASSWORD, DB_HOST, DB_PORT, DB_NAME
from .fmp_api import FMPAPI
import time
import numpy as np
import math
from dotenv import load_dotenv
import traceback
from .symbol_status_manager import update_symbol_status
from typing import Optional
import sqlalchemy as sa
from sqlalchemy.engine import Engine

class FMPDataFetcher:
    BASE_URL = "https://financialmodelingprep.com/stable"

    def __init__(self):
        self.api_key = API_KEY

    def fetch_daily_data(self, symbol):
        url = f"{self.BASE_URL}/historical-price-full?symbol={symbol}&apikey={self.api_key}"
        response = requests.get(url)
        if response.status_code == 200:
            return response.json()
        else:
            response.raise_for_status()

    def fetch_financial_statements(self, symbol):
        url = f"{self.BASE_URL}/income-statement?symbol={symbol}&apikey={self.api_key}"
        response = requests.get(url)
        if response.status_code == 200:
            return response.json()
        else:
            response.raise_for_status()

    def fetch_balance_sheet(self, symbol):
        url = f"{self.BASE_URL}/balance-sheet-statement?symbol={symbol}&apikey={self.api_key}"
        response = requests.get(url)
        if response.status_code == 200:
            return response.json()
        else:
            response.raise_for_status()

    def fetch_cash_flow(self, symbol):
        url = f"{self.BASE_URL}/cash-flow-statement?symbol={symbol}&apikey={self.api_key}"
        response = requests.get(url)
        if response.status_code == 200:
            return response.json()
        else:
            response.raise_for_status()

    def save_to_json(self, data, filename):
        with open(filename, 'w') as f:
            json.dump(data, f, indent=4)

    def process_dataframe_efficiently(self, df, chunk_size=10000):
        """
        データフレームを効率的に処理する
        
        パラメータ:
            df (DataFrame): 処理するデータフレーム
            chunk_size (int): チャンクサイズ
            
        戻り値:
            DataFrame: 処理済みのデータフレーム
        """
        try:
            if df.empty:
                return df
                
            # メモリ使用量の最適化
            for col in df.columns:
                # 数値型の最適化
                if df[col].dtype == 'float64':
                    # 小数点以下が不要な場合は整数に変換
                    if df[col].dropna().apply(lambda x: x.is_integer()).all():
                        df[col] = df[col].astype('Int64')
                    else:
                        # 必要な精度に合わせてfloat32に変換
                        df[col] = df[col].astype('float32')
                        
                # 文字列型の最適化
                elif df[col].dtype == 'object':
                    # カテゴリ型に変換可能な場合は変換
                    if df[col].nunique() / len(df) < 0.5:  # 50%以下のユニーク値
                        df[col] = df[col].astype('category')
                        
            # 日付型の最適化
            date_columns = df.select_dtypes(include=['datetime64']).columns
            for col in date_columns:
                df[col] = pd.to_datetime(df[col]).dt.date
                
            return df
            
        except Exception as e:
            self.logger.error(f"データフレーム処理中にエラーが発生: {e}")
            return df

    def fetch_and_store_historical_prices(self, symbol, days=30):
        """
        株価履歴データを取得して保存（メモリ効率化対応）
        
        パラメータ:
            symbol (str): 銘柄コード
            days (int): 取得する日数
            
        戻り値:
            bool: 成功時はTrue、失敗時はFalse
        """
        try:
            # データベースから最新日付を取得
            latest_date = self.get_latest_date(symbol, 'daily_prices')
            
            # 取得期間の設定
            if latest_date:
                from_date = (datetime.strptime(latest_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')
            else:
                from_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')
                
            to_date = datetime.now().strftime('%Y-%m-%d')
            
            # データの取得
            df = self.api.get_historical_price(symbol, from_date, to_date)
            
            if df.empty:
                self.logger.warning(f"{symbol}の株価データが取得できませんでした")
                return False
                
            # データフレームの効率的な処理
            df = self.process_dataframe_efficiently(df)
            
            # データベースに保存
            return self.save_to_database(df, "daily_prices")
            
        except Exception as e:
            self.logger.error(f"株価履歴データの処理エラー: {e}")
            return False

class FMPDataManager:
    """
    FMP API経由でデータを取得・保存するデータマネージャークラス
    - APIリクエストの管理、レート制限対応
    - 取得したデータの整形、変換
    - データベースへの保存処理
    """
    
    def __init__(self, db_conn_string=None):
        """
        初期化
        
        パラメータ:
            db_conn_string (str): データベース接続文字列
        """
        self.logger = logging.getLogger('fmp_data_manager')
        self.logger.setLevel(logging.INFO)
        
        # ハンドラがなければ追加
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
        
        # 接続文字列が指定されていない場合はデフォルト値を使用
        if db_conn_string is None:
            from src.utilities.config import DB_USER, DB_PASSWORD, DB_HOST, DB_PORT, DB_NAME
            db_conn_string = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
            
        # SQLAlchemyエンジンの作成
        self.db_engine = create_engine(db_conn_string)
        
        # API初期化
        self.api = FMPAPI()
        
        # APIリクエスト数カウンター
        self.request_count = 0
        self.api_request_count = {}  # エンドポイント別リクエスト数
        
        # データ取得量カウンター（バイト）
        self.data_size = 0

    def process_dataframe_efficiently(self, df, chunk_size=10000):
        """
        データフレームを効率的に処理する
        
        パラメータ:
            df (DataFrame): 処理するデータフレーム
            chunk_size (int): チャンクサイズ
            
        戻り値:
            DataFrame: 処理済みのデータフレーム
        """
        try:
            if df.empty:
                return df
                
            # メモリ使用量の最適化
            for col in df.columns:
                # 数値型の最適化
                if df[col].dtype == 'float64':
                    # 小数点以下が不要な場合は整数に変換
                    if df[col].dropna().apply(lambda x: x.is_integer()).all():
                        df[col] = df[col].astype('Int64')
                    else:
                        # 必要な精度に合わせてfloat32に変換
                        df[col] = df[col].astype('float32')
                        
                # 文字列型の最適化
                elif df[col].dtype == 'object':
                    # カテゴリ型に変換可能な場合は変換
                    if df[col].nunique() / len(df) < 0.5:  # 50%以下のユニーク値
                        df[col] = df[col].astype('category')
                        
            # 日付型の最適化
            date_columns = df.select_dtypes(include=['datetime64']).columns
            for col in date_columns:
                df[col] = pd.to_datetime(df[col]).dt.date
                
            return df
            
        except Exception as e:
            self.logger.error(f"データフレーム処理中にエラーが発生: {e}")
            return df

    def save_to_database(
        self,
        df: pd.DataFrame,
        table_name: str,
        engine: Engine,
        schema: str = "fmp_data",
        batch_size: int = 1000,
        update_on_conflict: bool = True,
        logger: Optional[logging.Logger] = None,
    ) -> int:
        """
        DataFrame をデータベースに保存する
        :param df: 保存するDataFrame
        :param table_name: テーブル名
        :param engine: SQLAlchemy エンジン
        :param schema: スキーマ名
        :param batch_size: バッチサイズ
        :param update_on_conflict: 競合時に更新するかどうか
        :param logger: ロガー
        :return: 保存された行数
        """
        if logger is None:
            logger = self.logger

        if df.empty:
            logger.info(f"{table_name}のデータは空のため、保存をスキップします")
            return 0

        # 日付列が複数ある場合は最初の日付列を使う
        date_columns = [col for col in df.columns if "date" in col.lower()]
        
        # DataFrameをコピーして使用する
        df_copy = df.copy()
        
        # 特殊なケース: sentiment_newsテーブルの場合は(symbol, published_date)がユニーク制約
        if table_name == "sentiment_news":
            conflict_keys = "title, url"
        else:
            # デフォルトは(symbol, date)をユニーク制約とする
            conflict_keys = "symbol, date" if "symbol" in df.columns and "date" in df.columns else None
        
        # 空の文字列をNULLに変換
        for col in df_copy.select_dtypes(include=["object"]).columns:
            df_copy[col] = df_copy[col].replace("", None)
            
        # データが有効かチェック
        for col in date_columns:
            if col in df_copy.columns and df_copy[col].isnull().any():
                logger.warning(f"列 '{col}' には NULL 値が含まれています。行数: {df_copy[col].isnull().sum()}")
                
        # テンポラリテーブル名の作成 (重複を避けるためにタイムスタンプを追加)
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        temp_table_name = f"temp_{table_name}_{timestamp}"
        
        # バッチ処理のためにデータを分割
        total_rows = len(df_copy)
        batch_count = (total_rows + batch_size - 1) // batch_size  # 切り上げ除算
        
        logger.info(f"{total_rows}行のデータを{batch_count}バッチに分割して保存します")
        
        rows_saved = 0
        
        try:
            with engine.begin() as conn:
                # バッチ処理
                for i in range(batch_count):
                    start_idx = i * batch_size
                    end_idx = min((i + 1) * batch_size, total_rows)
                    batch_df = df_copy.iloc[start_idx:end_idx]
                    
                    # 一時テーブルにデータを保存
                    batch_df.to_sql(
                        temp_table_name,
                        conn,
                        schema=schema,
                        if_exists="replace" if i == 0 else "append",
                        index=False,
                    )
                    
                    logger.debug(f"バッチ {i+1}/{batch_count} ({len(batch_df)}行) を一時テーブルに保存しました")
                    
                # 財務諸表テーブルの特殊なケース
                if table_name in ["income_statements", "balance_sheet_statements", "cash_flow_statements"]:
                    # 財務諸表テーブルの場合は(symbol, date, period)がユニーク制約
                    if update_on_conflict and conflict_keys:
                        # UPSERTクエリの作成
                        update_query = f"""
                        INSERT INTO {schema}.{table_name} 
                        SELECT * FROM {schema}.{temp_table_name}
                        ON CONFLICT (symbol, date, period) DO UPDATE SET
                        """
                        update_query += ", ".join([f"{col} = EXCLUDED.{col}" for col in df_copy.columns])
                        update_query += ";"
                        
                        conn.execute(sa.text(update_query))
                        logger.debug(f"INSERTクエリを実行: {update_query}")
                    else:
                        # 競合を無視して挿入
                        conn.execute(sa.text(f"INSERT INTO {schema}.{table_name} SELECT * FROM {schema}.{temp_table_name} ON CONFLICT DO NOTHING;"))
                        
                else:
                    # 通常のテーブルの場合
                    if update_on_conflict and conflict_keys:
                        # 列名のリストを取得
                        cols = list(df_copy.columns)
                        
                        # UPSERTクエリの作成
                        cols_str = ", ".join(cols)
                        update_stmts = ", ".join([f"{col} = EXCLUDED.{col}" for col in cols])
                        
                        query = f"""
                                INSERT INTO {schema}.{table_name} ({cols_str})
                                SELECT {cols_str} FROM {schema}.{temp_table_name}
                                ON CONFLICT ({conflict_keys}) DO UPDATE SET
                                    {update_stmts};
                                """
                        
                        conn.execute(sa.text(query))
                        logger.debug(f"INSERTクエリを実行: {query}")
                    else:
                        # 競合を無視して挿入
                        conn.execute(sa.text(f"INSERT INTO {schema}.{table_name} SELECT * FROM {schema}.{temp_table_name} ON CONFLICT DO NOTHING;"))
                        
                rows_saved = total_rows
                        
        except Exception as e:
            logger.error(f"バッチ {i+1} の保存中にエラーが発生: {e}")
            raise e
        finally:
            # テンポラリテーブルの削除を試みる
            try:
                with engine.begin() as conn:
                    conn.execute(sa.text(f"DROP TABLE IF EXISTS {schema}.{temp_table_name};"))
            except Exception as e:
                logger.warning(f"テンポラリテーブルの削除中にエラーが発生: {e}")
        
        return rows_saved
    
    def check_duplicate_entry(self, symbol, date, table_name, schema="fmp_data"):
        """
        データベースに重複エントリがあるかチェック
        
        パラメータ:
            symbol (str): 証券コード
            date (str): 日付
            table_name (str): テーブル名
            schema (str): スキーマ名
            
        戻り値:
            bool: 重複があればTrue、なければFalse
        """
        query = text(f"""
            SELECT 1 FROM {schema}.{table_name}
            WHERE symbol = :symbol AND date = :date
            LIMIT 1
        """)
        
        try:
            with self.db_engine.connect() as conn:
                result = conn.execute(query, {"symbol": symbol, "date": date})
                return result.fetchone() is not None
        except Exception as e:
            self.logger.error(f"重複チェックエラー: {e}")
            return False
    
    def get_latest_date(self, symbol, table_name, schema="fmp_data", period_type=None):
        """
        指定したテーブルの最新日付を取得
        
        パラメータ:
            symbol (str): 証券コード
            table_name (str): テーブル名
            schema (str): スキーマ名
            period_type (str): 'annual' または 'quarterly'（財務データの場合）
            
        戻り値:
            str: 最新日付（YYYY-MM-DD）または None
        """
        # 財務諸表テーブルの場合は、period_typeも条件に含める
        if table_name in ['income_statements', 'balance_sheets', 'cash_flows'] and period_type:
            query = text(f"""
                SELECT MAX(date) FROM {schema}.{table_name}
                WHERE symbol = :symbol AND period_type = :period_type
            """)
            
            try:
                with self.db_engine.connect() as conn:
                    result = conn.execute(query, {"symbol": symbol, "period_type": period_type})
                    max_date = result.scalar()
                    return max_date.strftime("%Y-%m-%d") if max_date else None
            except Exception as e:
                self.logger.error(f"最新日付取得エラー: {e}")
                return None
        else:
            # 通常のテーブルの場合
            query = text(f"""
                SELECT MAX(date) FROM {schema}.{table_name}
                WHERE symbol = :symbol
            """)
            
            try:
                with self.db_engine.connect() as conn:
                    result = conn.execute(query, {"symbol": symbol})
                    max_date = result.scalar()
                    return max_date.strftime("%Y-%m-%d") if max_date else None
            except Exception as e:
                self.logger.error(f"最新日付取得エラー: {e}")
                return None
    
    def fetch_and_store_income_statements(self, symbol, period_type="annual", is_japanese_stock=False):
        """
        損益計算書データを取得してデータベースに保存
        
        パラメータ:
            symbol (str): 証券コード
            period_type (str): 期間タイプ（annual または quarter）
            is_japanese_stock (bool): 日本株かどうか
            
        戻り値:
            tuple: (成功フラグ, データフレーム)
        """
        try:
            # データベースから最新日付を取得
            query = text("""
            SELECT MAX(date) as latest_date
            FROM fmp_data.income_statements
            WHERE symbol = :symbol
         AND period_type = :period_type
            """)
            
            with self.db_engine.connect() as conn:
                result = conn.execute(query, {"symbol": symbol, "period_type": period_type})
                row = result.fetchone()
                latest_date = row[0] if row and row[0] else None
            
            # 日本株の場合は専用エンドポイントを使用
            if is_japanese_stock or symbol.endswith('.T'):
                data = self.api.get_income_statements(symbol, period_type, is_japanese_stock=True)
            else:
                data = self.api.get_income_statements(symbol, period_type)
            
            # データがリスト型の場合はDataFrameに変換
            if isinstance(data, list):
                df = self.api.to_dataframe(data, period_type)
            else:
                df = data
            
            if df is None or df.empty:
                self.logger.warning(f"{symbol}の損益計算書データが取得できませんでした")
                return False, None
            
            # データベーススキーマに合わせてカラムを確認
            if 'company_name' in df.columns:
                df = df.drop(columns=['company_name'])
            
            # 問題のあるカラムを確認し削除（データ型の不一致を防ぐため）
            for col in df.columns:
                # 数値型であるべきカラムがテキスト型になっている場合は削除
                if df[col].dtype == 'object' and col not in ['symbol', 'reported_currency', 'cik', 'period', 'link', 'final_link', 'period_type', 'date']:
                    try:
                        # 数値変換を試みる
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                    except Exception as e:
                        # 変換できない場合は削除
                        self.logger.warning(f"カラム '{col}' が文字列型のため削除します（データベースは数値型を要求）: {e}")
                        df = df.drop(columns=[col])
            
            # 期間タイプを設定
            df['period_type'] = period_type
            
            # データベースに保存
            success = self.save_to_database(df, "income_statements")
            return success, df
        
        except Exception as e:
            self.logger.error(f"損益計算書データの処理エラー: {e}")
            return False, None
    
    def fetch_and_store_balance_sheets(self, symbol, period_type="annual", is_japanese_stock=False):
        """
        貸借対照表データを取得してデータベースに保存
        
        パラメータ:
            symbol (str): 証券コード
            period_type (str): 期間タイプ（annual または quarter）
            is_japanese_stock (bool): 日本株かどうか
            
        戻り値:
            tuple: (成功フラグ, データフレーム)
        """
        try:
            # データベースから最新日付を取得
            query = text("""
            SELECT MAX(date) as latest_date
            FROM fmp_data.balance_sheets
            WHERE symbol = :symbol
         AND period_type = :period_type
            """)
            
            with self.db_engine.connect() as conn:
                result = conn.execute(query, {"symbol": symbol, "period_type": period_type})
                row = result.fetchone()
                latest_date = row[0] if row and row[0] else None
            
            # 日本株の場合は専用エンドポイントを使用
            if is_japanese_stock or symbol.endswith('.T'):
                data = self.api.get_balance_sheets(symbol, period_type, is_japanese_stock=True)
            else:
                data = self.api.get_balance_sheets(symbol, period_type)
            
            # データがリスト型の場合はDataFrameに変換
            if isinstance(data, list):
                df = self.api.to_dataframe(data, period_type)
            else:
                df = data
            
            if df is None or df.empty:
                self.logger.warning(f"{symbol}の貸借対照表データが取得できませんでした")
                return False, None
            
            # データベーススキーマに合わせてカラムを確認
            if 'company_name' in df.columns:
                df = df.drop(columns=['company_name'])
            
            # 問題のあるカラムを確認し削除（データ型の不一致を防ぐため）
            for col in df.columns:
                # 数値型であるべきカラムがテキスト型になっている場合は削除
                if df[col].dtype == 'object' and col not in ['symbol', 'reported_currency', 'cik', 'period', 'link', 'final_link', 'period_type', 'date']:
                    try:
                        # 数値変換を試みる
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                    except Exception as e:
                        # 変換できない場合は削除
                        self.logger.warning(f"カラム '{col}' が文字列型のため削除します（データベースは数値型を要求）: {e}")
                        df = df.drop(columns=[col])
            
            # 期間タイプを設定
            df['period_type'] = period_type
            
            # データベースに保存
            success = self.save_to_database(df, "balance_sheets")
            return success, df
        
        except Exception as e:
            self.logger.error(f"貸借対照表データの処理エラー: {e}")
            return False, None
    
    def fetch_and_store_cash_flows(self, symbol, period_type="annual", is_japanese_stock=False):
        """
        キャッシュフロー計算書データを取得してデータベースに保存
        
        パラメータ:
            symbol (str): 証券コード
            period_type (str): 期間タイプ（annual または quarter）
            is_japanese_stock (bool): 日本株かどうか
            
        戻り値:
            tuple: (成功フラグ, データフレーム)
        """
        try:
            # データベースから最新日付を取得
            query = text("""
            SELECT MAX(date) as latest_date
            FROM fmp_data.cash_flows
            WHERE symbol = :symbol
         AND period_type = :period_type
            """)
            
            with self.db_engine.connect() as conn:
                result = conn.execute(query, {"symbol": symbol, "period_type": period_type})
                row = result.fetchone()
                latest_date = row[0] if row and row[0] else None
            
            # 日本株の場合は専用エンドポイントを使用
            if is_japanese_stock or symbol.endswith('.T'):
                data = self.api.get_cash_flows(symbol, period_type, is_japanese_stock=True)
            else:
                data = self.api.get_cash_flows(symbol, period_type)
            
            # データがリスト型の場合はDataFrameに変換
            if isinstance(data, list):
                df = self.api.to_dataframe(data, period_type)
            else:
                df = data
            
            if df is None or df.empty:
                self.logger.warning(f"{symbol}のキャッシュフロー計算書データが取得できませんでした")
                return False, None
            
            # データベーススキーマに合わせてカラムを確認
            if 'company_name' in df.columns:
                df = df.drop(columns=['company_name'])
            
            # カラム名マッピングの修正（不正なスペルを修正）
            column_mapping = {
                'other_investing_activites': 'other_investing_activities',
                'net_cash_used_for_investing_activites': 'net_cash_used_for_investing_activities',
                'other_financing_activites': 'other_financing_activities'
            }
            
            # カラム名の修正を適用
            for old_col, new_col in column_mapping.items():
                if old_col in df.columns:
                    self.logger.warning(f"不正なカラム名 '{old_col}' を '{new_col}' に修正します")
                    df = df.rename(columns={old_col: new_col})
            
            # 問題のあるカラムを確認し削除（データ型の不一致を防ぐため）
            for col in df.columns:
                # 数値型であるべきカラムがテキスト型になっている場合は削除
                if df[col].dtype == 'object' and col not in ['symbol', 'reported_currency', 'cik', 'period', 'link', 'final_link', 'period_type', 'date']:
                    try:
                        # 数値変換を試みる
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                    except Exception as e:
                        # 変換できない場合は削除
                        self.logger.warning(f"カラム '{col}' が文字列型のため削除します（データベースは数値型を要求）: {e}")
                        df = df.drop(columns=[col])
            
            # 期間タイプを設定
            df['period_type'] = period_type
            
            # データベースに保存
            success = self.save_to_database(df, "cash_flows")
            return success, df
        
        except Exception as e:
            self.logger.error(f"キャッシュフロー計算書データの処理エラー: {e}")
            return False, None
    
    def fetch_and_store_company_profile(self, symbol):
        """
        会社プロファイルデータを取得してデータベースに保存
        
        パラメータ:
            symbol (str): 証券コード
            
        戻り値:
            bool: 処理成功ならTrue、失敗ならFalse
        """
        try:
            # データの取得
            df = self.api.get_company_profile(symbol)
            
            if df.empty:
                self.logger.warning(f"{symbol}の会社プロファイルデータが取得できませんでした")
                return False
            
            # 現在の日付を追加
            df['date'] = datetime.now().strftime('%Y-%m-%d')
            
            # データベースに保存
            return self.save_to_database(df, "company_profile")
        
        except Exception as e:
            self.logger.error(f"会社プロファイルデータの処理エラー: {e}")
            return False
    
    def fetch_and_store_historical_prices(self, symbol, days=30):
        """
        株価履歴データを取得して保存（メモリ効率化対応）
        
        パラメータ:
            symbol (str): 銘柄コード
            days (int): 取得する日数
            
        戻り値:
            bool: 成功時はTrue、失敗時はFalse
        """
        try:
            # データベースから最新日付を取得
            latest_date = self.get_latest_date(symbol, 'daily_prices')
            
            # 取得期間の設定
            if latest_date:
                from_date = (datetime.strptime(latest_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')
            else:
                from_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')
                
            to_date = datetime.now().strftime('%Y-%m-%d')
            
            # データの取得
            df = self.api.get_historical_price(symbol, from_date, to_date)
            
            if df.empty:
                self.logger.warning(f"{symbol}の株価データが取得できませんでした")
                return False
                
            # データフレームの効率的な処理
            df = self.process_dataframe_efficiently(df)
            
            # データベースに保存
            return self.save_to_database(df, "daily_prices")
            
        except Exception as e:
            self.logger.error(f"株価履歴データの処理エラー: {e}")
            return False
    
    def fetch_and_store_news(self, symbol=None, limit=50):
        """
        ニュースデータを取得してデータベースに保存
        
        パラメータ:
            symbol (str): 証券コード（Noneなら全銘柄）
            limit (int): 取得するニュース数
            
        戻り値:
            bool: 処理成功ならTrue、失敗ならFalse
        """
        try:
            # データの取得
            df = self.api.get_news(symbol, limit)
            
            if df.empty:
                self.logger.warning(f"ニュースデータが取得できませんでした")
                return False
            
            # カラム名をスネークケースに変換
            df = df.rename(columns={
                'publishedDate': 'published_date',
                'siteName': 'site_name'
            })
            
            # 取得日時の列を追加
            df['retrieved_at'] = pd.to_datetime('today').strftime('%Y-%m-%d %H:%M:%S')
            
            # ニュース情報をテーブルに保存前に重複チェック
            unique_news = []
            news_ids = set()
            
            # 既存のニュースIDを取得
            try:
                # 最新日付を取得
                latest_date = None
                with self.db_engine.connect() as conn:
                    result = conn.execute(text(
                        """
                        SELECT MAX(published_date) as latest_date
                        FROM fmp_data.news
                        """
                    ))
                    row = result.fetchone()
                    if row and row[0]:
                        latest_date = row[0]
                        
                        # 過去1週間分のニュースタイトルとURLを取得（重複チェック用）
                        result = conn.execute(text(
                            """
                            SELECT title, url
                            FROM fmp_data.news
                            WHERE published_date >= :latest_date
                            """),
                            {"latest_date": latest_date - timedelta(days=7)}
                        )
                        for row in result:
                            news_ids.add(f"{row[0]}:{row[1]}")
            except Exception as e:
                self.logger.warning(f"既存ニュースの取得中にエラーが発生しました: {e}")
            
            # 重複チェック
            for _, row in df.iterrows():
                news_id = f"{row.get('title')}:{row.get('url')}"
                if news_id not in news_ids:
                    news_ids.add(news_id)
                    unique_news.append(row)
            
            if not unique_news:
                self.logger.warning("新しいニュースデータがありませんでした")
                return False
            
            # 重複排除したデータを新しいDataFrameに変換
            unique_df = pd.DataFrame(unique_news)
            
            # データベースに保存（newsテーブルに）
            return self.save_to_database(unique_df, "news")
        
        except Exception as e:
            self.logger.error(f"ニュースデータの処理エラー: {e}")
            self.logger.error(traceback.format_exc())
            return False
    
    def update_sentiment_news(self, pages=10, duplicate_threshold=0.7):
        """
        センチメント分析付きニュースデータを更新する
        
        パラメータ:
            pages (int): 取得する最大ページ数
            duplicate_threshold (float): 重複率がこの値を超えたら中止（0.0～1.0）
            
        戻り値:
            int: 更新されたニュース件数
        """
        try:
            return self.fetch_and_store_sentiment_news(pages, duplicate_threshold)
        except Exception as e:
            logging.error(f"センチメントニュースデータの更新中にエラーが発生しました: {e}")
            return 0
            
    def fetch_and_store_sentiment_news(self, pages=10, duplicate_threshold=0.7):
        """
        センチメント分析付きニュースデータを取得しDBに保存する
        
        パラメータ:
            pages (int): 取得する最大ページ数
            duplicate_threshold (float): 重複率がこの値を超えたら中止（0.0～1.0）
            
        戻り値:
            int: 取得・保存されたニュースの件数
        """
        try:
            all_news = []
            
            # 最新のニュース日付を取得
            latest_date = None
            try:
                with self.db_engine.connect() as conn:
                    result = conn.execute(text(
                        """
                        SELECT MAX(published_date) as latest_date
                        FROM fmp_data.sentiment_news
                        """
                    ))
                    row = result.fetchone()
                    if row and row[0]:
                        latest_date = row[0]
                        # タイムゾーン情報をUTCに統一
                        if latest_date.tzinfo is not None:
                            latest_date = latest_date.astimezone(timezone.utc)
                        self.logger.info(f"最新のニュース日付: {latest_date} (UTC)")
            except Exception as e:
                self.logger.warning(f"最新ニュース日付の取得中にエラーが発生しました: {e}")
            
            # 重複チェック用のセット
            news_ids = set()
            
            # 既存のニュースIDを取得（タイトルと公開日時）
            try:
                if latest_date:
                    with self.db_engine.connect() as conn:
                        result = conn.execute(text(
                            """
                            SELECT title, published_date
                            FROM fmp_data.sentiment_news
                            WHERE published_date >= :latest_date
                            """),
                            {"latest_date": latest_date - timedelta(days=7)}  # 過去7日分をチェック
                        )
                        for row in result:
                            if row[0] and row[1]:  # タイトルと公開日時の両方が存在する場合のみ追加
                                # タイムゾーン情報をUTCに統一してキー作成
                                pub_date = row[1]
                                if pub_date.tzinfo is not None:
                                    pub_date = pub_date.astimezone(timezone.utc)
                                news_ids.add(f"{row[0]}:{pub_date}")
                        self.logger.info(f"重複チェック用に{len(news_ids)}件の既存ニュースIDを取得しました")
            except Exception as e:
                self.logger.warning(f"既存ニュースID取得中にエラーが発生しました: {e}")
            
            # デバッグログ用
            skipped_by_date = 0
            skipped_by_id = 0
            total_processed = 0
            total_new = 0
            
            # 確認用に新しいニュースのタイトルと日付を収集
            new_news_titles = []
            
            for page in range(pages):
                self.logger.info(f"センチメントニュースのページ {page+1}/{pages} を取得中...")
                # レスポンスのJSON構造を直接調査して処理
                # DataFrameからdict形式のレコードに変換せず、直接APIレスポンスを使用
                raw_news_data = self.api.get_sentiment_news_raw(page)
                
                # サンプルデータをログに出力
                if len(raw_news_data) > 0:
                    sample = raw_news_data[0]
                    has_pub_date = 'publishedDate' in sample and sample['publishedDate']
                    pub_date_str = sample.get('publishedDate', 'なし')
                    self.logger.info(f"サンプルニュース: 日付={pub_date_str}, タイトル={sample.get('title', 'なし')[:30]}...")
                    if not has_pub_date:
                        self.logger.warning("APIレスポンスに公開日付(publishedDate)が含まれていないか空です")
                
                # 公開日付の欠損状況を確認
                missing_dates = sum(1 for item in raw_news_data if 'publishedDate' not in item or not item.get('publishedDate'))
                if missing_dates > 0:
                    self.logger.warning(f"ページ{page+1}で{missing_dates}件のニュースに公開日付が設定されていません")
                
                # 重複チェックカウンター
                total_items = len(raw_news_data)
                duplicate_count = 0
                page_new_items = 0
                
                # 重複チェックと過去データフィルタリング
                new_items = []
                
                for item in raw_news_data:
                    total_processed += 1
                    
                    # publishedDateがない場合は処理をスキップして次の項目へ
                    if 'publishedDate' not in item or not item.get('publishedDate'):
                        self.logger.debug(f"公開日が指定されていないニュースをスキップします: {item.get('title', 'タイトルなし')}")
                        continue
                    
                    # タイトルのチェック
                    title = item.get('title', '')
                    if not title:
                        continue  # タイトルがない場合はスキップ
                        
                    # 日付の変換
                    try:
                        item_date = pd.to_datetime(item.get('publishedDate'))
                        # タイムゾーン情報がない場合はUTCとして扱う
                        if item_date.tzinfo is None:
                            item_date = item_date.replace(tzinfo=timezone.utc)
                        else:
                            # タイムゾーン情報をUTCに統一
                            item_date = item_date.astimezone(timezone.utc)
                    except (ValueError, TypeError) as e:
                        self.logger.warning(f"日付の変換に失敗しました: {e} - {item.get('publishedDate')}")
                        continue  # 日付に問題がある場合は、次のアイテムに進む
                    
                    # タイトルと公開日時で一意性を判断
                    news_id = f"{title}:{item_date}"
                    
                    # デバッグログ出力
                    if total_processed <= 3 or (total_processed % 50 == 0):
                        self.logger.info(f"処理中のアイテム: {title[:30]}..., 日付={item_date}")
                        if latest_date:
                            self.logger.info(f"日付比較: item_date({item_date}) vs latest_date({latest_date}), 比較結果={item_date > latest_date}")
                    
                    # 日付チェック（最新日付より古いデータはスキップ）
                    if latest_date and item_date and item_date <= latest_date:
                        skipped_by_date += 1
                        duplicate_count += 1
                        if skipped_by_date <= 3:
                            self.logger.info(f"日付が古いためスキップ: {title[:30]}..., 日付={item_date}, 最新日付={latest_date}")
                        continue  # 古いデータなのでスキップ
                    
                    # ID重複チェック
                    if news_id in news_ids:
                        skipped_by_id += 1
                        duplicate_count += 1
                        if skipped_by_id <= 3:
                            self.logger.info(f"ID重複のためスキップ: {title[:30]}..., 日付={item_date}")
                        continue  # 既存IDと重複するのでスキップ
                    
                    # 新しいアイテムとして追加
                    news_ids.add(news_id)
                    new_items.append(item)
                    page_new_items += 1
                    
                    # 新しいニュースの情報をログ用に保存
                    if len(new_news_titles) < 5:  # 最初の5件のみ保存
                        new_news_titles.append(f"{title[:30]}...(日付: {item_date})")
                
                all_news.extend(new_items)
                total_new += page_new_items
                self.logger.info(f"ページ{page+1}から{page_new_items}件の新しいニュースを追加しました")
                
                # 重複率の計算と中止判定
                if total_items > 0:
                    duplicate_rate = duplicate_count / total_items
                    self.logger.info(f"ページ{page+1}の重複率: {duplicate_rate:.2f} ({duplicate_count}/{total_items})")
                    
                    if duplicate_rate >= duplicate_threshold:
                        self.logger.info(f"重複率が閾値({duplicate_threshold:.2f})を超えたため、以降のページ取得を中止します")
                        break
            
            # 処理サマリーをログに出力
            self.logger.info(f"処理サマリー: 合計{total_processed}件処理、{total_new}件追加、{skipped_by_date}件は日付による除外、{skipped_by_id}件はID重複による除外")
            
            # 新しいニュースのサンプルを表示
            if new_news_titles:
                self.logger.info(f"新しく追加されるニュースのサンプル: {', '.join(new_news_titles)}")
            
            if not all_news:
                self.logger.warning("新しいセンチメントニュースデータが見つかりませんでした")
                return 0
            
            # データをデータフレームに変換
            df = pd.DataFrame(all_news)
            
            # カラム名をスネークケースに変換
            df = df.rename(columns={
                'publishedDate': 'published_date',
                'sentimentScore': 'sentiment_score'
            })
            
            # 日付カラムを適切に変換
            df['published_date'] = pd.to_datetime(df['published_date'])
            
            # 取得日時の列を追加
            df['retrieved_at'] = pd.to_datetime('today').strftime('%Y-%m-%d %H:%M:%S')
            
            # データをDBに保存
            self.logger.info(f"{len(df)}件の新しいセンチメントニュースをデータベースに保存します")
            result = self.save_to_database(df, 'sentiment_news', self.db_engine)
            
            if result:
                self.logger.info(f"センチメントニュースの保存に成功しました: {len(df)}件")
            else:
                self.logger.error("センチメントニュースの保存に失敗しました")
                
            return len(df) if result else 0
            
        except Exception as e:
            self.logger.error(f"センチメントニュースデータの取得・保存中にエラーが発生しました: {e}")
            self.logger.error(traceback.format_exc())
            return 0
    
    def fetch_and_store_shares(self, symbol):
        """
        株式数データを取得してデータベースに保存
        
        パラメータ:
            symbol (str): 証券コード
            
        戻り値:
            bool: 処理成功ならTrue、失敗ならFalse
        """
        try:
            # データベースから最新日付を取得
            latest_date = self.get_latest_date(symbol, 'shares')
            
            # 最新日付がある場合、その翌日以降のデータを取得
            from_date = None
            if latest_date:
                from_date = (datetime.strptime(latest_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')
                self.logger.info(f"{symbol}の株式数データを{from_date}以降から取得します")
            else:
                self.logger.info(f"{symbol}の株式数データを全期間取得します")
            
            # データの取得
            df = self.api.get_shares_float(symbol, from_date=from_date)
            
            if df.empty:
                self.logger.warning(f"{symbol}の株式数データが取得できませんでした")
                # 株価データの取得状況を確認
                latest_price_date = self.get_latest_date(symbol, 'daily_prices')
                if not latest_price_date:
                    self.logger.warning(f"{symbol}の株価データも取得できていないため、銘柄ステータスを非アクティブに更新します")
                    self._update_symbol_status(symbol, is_active=False)
                    return False
                return True
            
            # カラム名をスネークケースに変換
            df = df.rename(columns={
                'freeFloat': 'free_float',
                'floatShares': 'float_shares',
                'outstandingShares': 'outstanding_shares'
            })
            
            # float_sharesとoutstanding_sharesをbigintに変換
            if 'float_shares' in df.columns:
                df['float_shares'] = pd.to_numeric(df['float_shares'], errors='coerce')
            
            if 'outstanding_shares' in df.columns:
                df['outstanding_shares'] = pd.to_numeric(df['outstanding_shares'], errors='coerce')
            
            # データベースに保存
            return self.save_to_database(df, "shares")
        
        except Exception as e:
            self.logger.error(f"株式数データの処理エラー: {e}")
            self.logger.error(traceback.format_exc())
            # 株価データの取得状況を確認
            latest_price_date = self.get_latest_date(symbol, 'daily_prices')
            if not latest_price_date:
                self.logger.warning(f"{symbol}の株価データも取得できていないため、銘柄ステータスを非アクティブに更新します")
                self._update_symbol_status(symbol, is_active=False)
                return False
            return True
    
    def fetch_and_store_employee_count(self, symbol):
        """従業員数データを取得しDBに保存する"""
        try:
            # 現在のデータの最新年度を取得
            latest_year = None
            try:
                with self.db_engine.connect() as conn:
                    result = conn.execute(text(
                        """
                        SELECT MAX(EXTRACT(YEAR FROM period_of_report::date)) as latest_year
                        FROM fmp_data.employee_counts
                        WHERE symbol = :symbol
                        """),
                        {"symbol": symbol}
                    )
                    row = result.fetchone()
                    if row and row[0]:
                        latest_year = int(row[0])
                        # 現在年から最新年を引いて、必要なlimitを計算
                        current_year = datetime.now().year
                        limit = current_year - latest_year
                        if limit <= 0:
                            # すでに最新データがある場合は1（最小値）を設定
                            limit = 1
                        else:
                            # 安全のために+1年追加
                            limit = limit + 1
                    else:
                        # データがない場合、デフォルトで5年分取得
                        limit = 5
            except Exception as e:
                self.logger.warning(f"{symbol}の従業員数データの最新年度取得中にエラーが発生しました: {e}")
                # エラーが発生した場合、デフォルトで5年分取得
                limit = 5
            
            self.logger.info(f"{symbol}の従業員数データを取得します（limit={limit}）")
            employee_data = self.api.get_employee_count(symbol, limit=limit)
            
            if not employee_data or len(employee_data) == 0:
                self.logger.warning(f"{symbol}の従業員数データが見つかりませんでした")
                return False
            
            # データをデータフレームに変換
            df = pd.DataFrame(employee_data)
            
            # symbol列がなければ追加
            if 'symbol' not in df.columns:
                df['symbol'] = symbol
            
            # データをDBに保存（テーブル名をemployee_countsに変更）
            return self.save_to_database(df, 'employee_counts')
        except Exception as e:
            self.logger.error(f"{symbol}の従業員数データの取得・保存中にエラーが発生しました: {e}")
            return False

    def update_forex_data(self, pairs=None, forex_config_file=None):
        """為替データを更新する
        
        パラメータ:
            pairs (list): 更新する通貨ペアのリスト（デフォルト: None）
            forex_config_file (str): 通貨ペアが記載されたJSONファイルのパス
            
        戻り値:
            bool: 少なくとも1つの通貨ペアの更新に成功した場合はTrue
        """
        import traceback
        import json
        import os
        
        # 通貨ペアの取得順序:
        # 1. 引数で直接指定された通貨ペア
        # 2. 設定ファイルからの通貨ペア
        # 3. デフォルトの通貨ペア
        
        if pairs is None:
            # 設定ファイルから読み込み
            if forex_config_file is None:
                # デフォルトはプロジェクトルートのconfig/forex_config.json
                project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
                forex_config_file = os.path.join(project_root, "config", "forex_config.json")
                
            if os.path.exists(forex_config_file):
                try:
                    with open(forex_config_file, 'r') as f:
                        config = json.load(f)
                        if 'forex_pairs' in config and isinstance(config['forex_pairs'], list):
                            pairs = config['forex_pairs']
                            self.logger.info(f"設定ファイル {forex_config_file} から {len(pairs)} 個の通貨ペアを読み込みました")
                except Exception as e:
                    self.logger.error(f"為替設定ファイルの読み込みエラー: {e}")
                    self.logger.error(traceback.format_exc())
            
            # デフォルト値
            if pairs is None or len(pairs) == 0:
                pairs = ['USDJPY', 'EURUSD', 'GBPUSD', 'USDCAD', 'AUDUSD', 'USDCHF']
                self.logger.info(f"デフォルトの通貨ペア {len(pairs)} 個を使用します")
        else:
            self.logger.info(f"指定された {len(pairs)} 個の通貨ペアを使用します")
            
        self.logger.info("為替データを取得しています...")
        
        results = {}
        success_count = 0
        
        for pair in pairs:
            try:
                # 最新データの日付を取得
                latest_date = None
                try:
                    with self.db_engine.connect() as conn:
                        result = conn.execute(text(f"""
                            SELECT MAX(date) FROM fmp_data.forex
                            WHERE symbol = '{pair}'
                        """))
                        latest_date = result.fetchone()[0]
                except Exception as e:
                    self.logger.warning(f"{pair}の最新データ取得中にエラーが発生しました: {e}")
                
                # 取得期間の設定
                if latest_date:
                    # 最新日付の翌日から今日まで
                    from_date = (latest_date + timedelta(days=1)).strftime('%Y-%m-%d')
                    self.logger.info(f"{pair}の最新データは {latest_date} です。{from_date} から取得します。")
                else:
                    # データがない場合は過去30日分を取得
                    from_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
                    self.logger.info(f"{pair}のデータが存在しないため、{from_date}から取得します")
                
                to_date = datetime.now().strftime('%Y-%m-%d')
                
                # 同じ日のデータしかない場合はスキップ
                if latest_date and latest_date.strftime('%Y-%m-%d') == datetime.now().strftime('%Y-%m-%d'):
                    self.logger.info(f"{pair}のデータは最新です（{latest_date}）")
                    results[pair] = True
                    success_count += 1
                    continue
                
                # FMP APIから為替データを取得
                self.logger.info(f"{pair}の為替データを{from_date}から{to_date}まで取得します")
                forex_data = self.api.get_forex(pair, from_date=from_date, to_date=to_date)
                
                # データチェック
                if forex_data is None or len(forex_data) == 0:
                    self.logger.warning(f"{pair}の為替データが見つかりませんでした")
                    results[pair] = False
                    continue
                
                # APIからのデータを確認
                if isinstance(forex_data, pd.DataFrame):
                    # カラム名の確認
                    self.logger.debug(f"APIから取得したカラム: {forex_data.columns.tolist()}")
                    
                    # 必要なカラムがあるか確認
                    required_cols = ['date']
                    price_col = None
                    volume_col = None
                    
                    # 価格用のカラムを検索
                    for col in ['close', 'price', forex_data.columns[-1]]:
                        if col in forex_data.columns:
                            price_col = col
                            break
                    
                    # 出来高用のカラムを検索
                    if 'volume' in forex_data.columns:
                        volume_col = 'volume'
                    
                    if price_col is None:
                        self.logger.error(f"価格カラムが見つかりません: {forex_data.columns.tolist()}")
                        results[pair] = False
                        continue
                    
                    if 'date' not in forex_data.columns:
                        self.logger.error(f"dateカラムが見つかりません: {forex_data.columns.tolist()}")
                        results[pair] = False
                        continue
                
                # データベースに保存
                with self.db_engine.connect() as conn:
                    try:
                        # 最新データ以降のみフィルタリング
                        if latest_date:
                            forex_data = forex_data[forex_data['date'] > latest_date]
                        
                        if len(forex_data) == 0:
                            self.logger.info(f"{pair}の最新データはすでに保存されています")
                            results[pair] = True
                            success_count += 1
                            continue
                        
                        # データベースに挿入
                        inserted_count = 0
                        for idx, row in forex_data.iterrows():
                            # 日付とシンボルは必須
                            if not pd.isna(row['date']):
                                try:
                                    # 価格は必須、出来高はオプション
                                    price_value = row[price_col] if not pd.isna(row[price_col]) else 0
                                    volume_value = row[volume_col] if volume_col and volume_col in row.index and not pd.isna(row[volume_col]) else None
                                    
                                    # データ確認
                                    self.logger.debug(f"挿入データ: symbol={pair}, date={row['date']}, price={price_value}, volume={volume_value}")
                                    
                                    conn.execute(text("""
                                        INSERT INTO fmp_data.forex (symbol, date, price, volume)
                                        VALUES (:symbol, :date, :price, :volume)
                                        ON CONFLICT (symbol, date) DO UPDATE SET
                                            price = EXCLUDED.price,
                                            volume = EXCLUDED.volume
                                    """), {
                                        'symbol': pair,
                                        'date': row['date'],
                                        'price': price_value,
                                        'volume': volume_value
                                    })
                                    inserted_count += 1
                                except Exception as e:
                                    self.logger.error(f"{pair}の行データ挿入中にエラー: {e}, 行データ: {row.to_dict()}")
                    
                        conn.commit()
                        self.logger.info(f"{pair}の為替データ {inserted_count} 件を保存しました")
                        results[pair] = True
                        success_count += 1
                        
                    except Exception as e:
                        self.logger.error(f"{pair}の為替データの保存中にエラーが発生しました: {e}")
                        self.logger.error(traceback.format_exc())
                        results[pair] = False
                        conn.rollback()
                
            except Exception as e:
                self.logger.error(f"{pair}の為替データの取得・保存中にエラーが発生しました: {e}")
                self.logger.error(traceback.format_exc())
                results[pair] = False
        
        # 結果のデバッグ表示
        self.logger.debug(f"通貨ペアごとの結果: {results}")
        
        # 全体の結果を返す
        for pair, result in results.items():
            self.logger.info(f" - {pair}: {'成功' if result else '失敗'}")
        
        # 少なくとも1つ成功していれば成功とみなす    
        return success_count > 0
    
    def fetch_and_store_earnings_calendar(self, from_date, to_date=None):
        """
        決算発表カレンダーを取得してデータベースに保存
        
        パラメータ:
            from_date (str): 開始日（YYYY-MM-DD形式）
            to_date (str): 終了日（YYYY-MM-DD形式）、Noneの場合は開始日と同じ
            
        戻り値:
            DataFrame: 保存した決算発表カレンダーデータ
        """
        try:
            # データの取得
            df = self.api.get_earnings_calendar(from_date, to_date)
            
            if df.empty:
                self.logger.warning(f"{from_date}～{to_date}の決算発表カレンダーデータが取得できませんでした")
                return pd.DataFrame()
            
            # カラム名の標準化
            if 'date' in df.columns:
                df = df.rename(columns={'date': 'report_date'})
            
            # 最終更新日を追加
            df['last_updated'] = pd.to_datetime('today').strftime('%Y-%m-%d')
            
            # データベースへの保存処理
            try:
                # ON CONFLICT DO UPDATEを使用して、既存データを更新
                with self.db_engine.connect() as conn:
                    # 一時テーブルを作成して挿入
                    tmp_table = f"tmp_earnings_calendar_{datetime.now().strftime('%Y%m%d%H%M%S')}"
                    df.to_sql(tmp_table, conn, schema='fmp_data', if_exists='replace', index=False)
                    
                    # UPSERTクエリ
                    query = f"""
                    INSERT INTO fmp_data.earnings_calendar (
                        symbol, report_date, eps_actual, eps_estimated, 
                        revenue_actual, revenue_estimated, last_updated
                    )
                    SELECT 
                        symbol, report_date, eps_actual, eps_estimated, 
                        revenue_actual, revenue_estimated, last_updated
                    FROM fmp_data.{tmp_table}
                    ON CONFLICT (symbol, report_date)
                    DO UPDATE SET
                        eps_actual = EXCLUDED.eps_actual,
                        eps_estimated = EXCLUDED.eps_estimated,
                        revenue_actual = EXCLUDED.revenue_actual,
                        revenue_estimated = EXCLUDED.revenue_estimated,
                        last_updated = EXCLUDED.last_updated;
                    """
                    
                    conn.execute(text(query))
                    
                    # 一時テーブルを削除
                    conn.execute(text(f"DROP TABLE fmp_data.{tmp_table};"))
                    
                    self.logger.info(f"決算発表カレンダーデータを正常に保存/更新しました（{len(df)}件）")
                    return df
            except Exception as e:
                self.logger.error(f"決算発表カレンダーUPSERT処理エラー: {e}")
                self.logger.error(traceback.format_exc())
                
                # 通常の方法で保存を試みる
                success = self.save_to_database(df, "earnings_calendar")
                if not success:
                    self.logger.error("決算発表カレンダーの保存に失敗しました")
                    return pd.DataFrame()
                
                return df
            
        except Exception as e:
            self.logger.error(f"決算発表カレンダーデータの処理エラー: {e}")
            self.logger.error(traceback.format_exc())
            return pd.DataFrame()
    
    def update_financials_based_on_earnings(self, from_date, to_date=None, days_buffer=1):
        """
        決算発表があった銘柄の財務データを更新
        
        パラメータ:
            from_date (str): 開始日（YYYY-MM-DD形式）
            to_date (str): 終了日（YYYY-MM-DD形式）、Noneの場合は開始日と同じ
            days_buffer (int): 決算発表日からの取得猶予日数
            
        戻り値:
            dict: 更新結果の辞書 {symbol: {'status': bool, 'reason': str}}
        """
        try:
            # 決算発表カレンダーを取得
            earnings_df = self.fetch_and_store_earnings_calendar(from_date, to_date)
            
            if earnings_df.empty:
                self.logger.warning("決算発表カレンダーが空のため、財務データの更新をスキップします")
                return {}
                
            # 決算発表日が過去の銘柄を抽出
            today = datetime.now().date()
            
            # date列がない場合は'date'列を作成
            if 'date' not in earnings_df.columns:
                # dateカラムがなければ、eps_dateかreport_dateを使用
                if 'eps_date' in earnings_df.columns:
                    earnings_df['date'] = pd.to_datetime(earnings_df['eps_date']).dt.date
                elif 'report_date' in earnings_df.columns:
                    earnings_df['date'] = pd.to_datetime(earnings_df['report_date']).dt.date
                else:
                    self.logger.error("決算発表カレンダーに日付情報がありません")
                    return {}
            else:
                # date列を日付型に変換
                earnings_df['date'] = pd.to_datetime(earnings_df['date']).dt.date
                
            # 決算発表日が指定日数前までの銘柄を抽出
            available_date = today - timedelta(days=days_buffer)
            announced_earnings = earnings_df[earnings_df['date'] <= available_date]
            
            if announced_earnings.empty:
                self.logger.info(f"指定期間内に決算発表が完了している銘柄はありません（猶予期間: {days_buffer}日）")
                return {}
                
            # 銘柄ごとに財務データを更新
            results = {}
            symbols_to_update = announced_earnings['symbol'].unique()
            
            for symbol in symbols_to_update:
                self.logger.info(f"{symbol}の決算発表が確認されたため、財務データを更新します")
                symbol_result = {}
                
                try:
                    # 年次データ更新を試みる
                    symbol_result['income_annual'] = self.fetch_and_store_income_statements(symbol, 'annual')
                    symbol_result['balance_annual'] = self.fetch_and_store_balance_sheets(symbol, 'annual')
                    symbol_result['cashflow_annual'] = self.fetch_and_store_cash_flows(symbol, 'annual')
                    
                    # 四半期データ更新を試みる
                    symbol_result['income_quarter'] = self.fetch_and_store_income_statements(symbol, 'quarter')
                    symbol_result['balance_quarter'] = self.fetch_and_store_balance_sheets(symbol, 'quarter')
                    symbol_result['cashflow_quarter'] = self.fetch_and_store_cash_flows(symbol, 'quarter')
                    
                    # 結果を記録
                    success = any(symbol_result.values())
                    symbol_result['status'] = success
                    symbol_result['reason'] = "更新成功" if success else "すべての財務データの更新に失敗"
                    
                except Exception as e:
                    self.logger.error(f"{symbol}の財務データ更新中にエラー発生: {e}")
                    symbol_result['status'] = False
                    symbol_result['reason'] = f"エラー: {str(e)}"
                
                results[symbol] = symbol_result
            
            # 更新に失敗した銘柄を記録
            failed_symbols = [symbol for symbol, result in results.items() if not result['status']]
            if failed_symbols:
                self.logger.warning(f"財務データの更新に失敗した銘柄: {', '.join(failed_symbols)}")
                self._save_failed_symbols(failed_symbols)
                
            return results
                
        except Exception as e:
            self.logger.error(f"決算発表に基づく財務データ更新処理エラー: {e}")
            return {}
    
    def _save_failed_symbols(self, symbols, filename="failed_financial_updates.txt"):
        """
        財務データの更新に失敗した銘柄をファイルに保存
        
        パラメータ:
            symbols (list): 失敗した銘柄のリスト
            filename (str): 保存するファイル名
        """
        try:
            # ファイルが存在しない場合は新規作成
            if not os.path.exists(filename):
                with open(filename, 'w') as f:
                    f.write(f"# 財務データ更新失敗銘柄リスト (更新: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n")
            
            # 既存の失敗リストを読み込み
            existing_symbols = set()
            if os.path.exists(filename):
                with open(filename, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if not line or line.startswith('#'):
                            continue
                        existing_symbols.add(line)
            
            # 新しい失敗銘柄を追加
            all_symbols = existing_symbols.union(set(symbols))
            
            # ファイルに書き出し
            with open(filename, 'w') as f:
                f.write(f"# 財務データ更新失敗銘柄リスト (更新: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n")
                for symbol in sorted(all_symbols):
                    f.write(f"{symbol}\n")
                    
            self.logger.info(f"財務データ更新失敗銘柄リストを{filename}に保存しました（合計: {len(all_symbols)}銘柄）")
            
        except Exception as e:
            self.logger.error(f"失敗銘柄リストの保存エラー: {e}")
    
    def update_from_failed_symbols_list(self, filename="failed_financial_updates.txt"):
        """
        過去に失敗した銘柄の財務データを再更新
        
        パラメータ:
            filename (str): 失敗銘柄リストファイル名
            
        戻り値:
            dict: 更新結果
        """
        try:
            if not os.path.exists(filename):
                self.logger.info(f"失敗銘柄リストファイル{filename}が見つかりません")
                return {}
                
            # 失敗銘柄リストを読み込み
            symbols = []
            with open(filename, 'r') as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith('#'):
                        continue
                    symbols.append(line)
                    
            if not symbols:
                self.logger.info("更新失敗銘柄リストは空です")
                return {}
                
            self.logger.info(f"更新失敗銘柄リストから{len(symbols)}銘柄の財務データを更新します")
            
            # 銘柄ごとに財務データを更新
            results = {}
            successful_symbols = []
            
            for symbol in symbols:
                self.logger.info(f"失敗リストから{symbol}の財務データを更新します")
                symbol_result = {}
                
                try:
                    # 年次データ更新を試みる
                    symbol_result['income_annual'] = self.fetch_and_store_income_statements(symbol, 'annual')
                    symbol_result['balance_annual'] = self.fetch_and_store_balance_sheets(symbol, 'annual')
                    symbol_result['cashflow_annual'] = self.fetch_and_store_cash_flows(symbol, 'annual')
                    
                    # 四半期データ更新を試みる
                    symbol_result['income_quarter'] = self.fetch_and_store_income_statements(symbol, 'quarter')
                    symbol_result['balance_quarter'] = self.fetch_and_store_balance_sheets(symbol, 'quarter')
                    symbol_result['cashflow_quarter'] = self.fetch_and_store_cash_flows(symbol, 'quarter')
                    
                    # 結果を記録
                    success = any(symbol_result.values())
                    symbol_result['status'] = success
                    
                    if success:
                        successful_symbols.append(symbol)
                    
                except Exception as e:
                    self.logger.error(f"{symbol}の財務データ更新中にエラー発生: {e}")
                    symbol_result['status'] = False
                
                results[symbol] = symbol_result
            
            # 更新に成功した銘柄をリストから削除
            if successful_symbols:
                self.logger.info(f"{len(successful_symbols)}銘柄の更新に成功しました")
                
                # 残りの失敗銘柄リストを更新
                remaining_symbols = [s for s in symbols if s not in successful_symbols]
                
                # ファイルに書き出し
                with open(filename, 'w') as f:
                    f.write(f"# 財務データ更新失敗銘柄リスト (更新: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n")
                    for symbol in sorted(remaining_symbols):
                        f.write(f"{symbol}\n")
                        
                self.logger.info(f"財務データ更新失敗銘柄リストを更新しました（残り: {len(remaining_symbols)}銘柄）")
            
            return results
                
        except Exception as e:
            self.logger.error(f"失敗銘柄リストからの更新エラー: {e}")
            return {}
            
    def update_all_data_for_symbols(self, symbols):
        """複数銘柄の全データを更新する"""
        results = {}
        
        for symbol in symbols:
            logging.info(f"{symbol}の全データを更新します")
            results[symbol] = self.update_all_data_for_symbol(symbol)
            
        return results

    def update_all_data_for_symbol(self, symbol):
        """1つの銘柄の全データを更新する"""
        results = {}
        
        # 会社プロファイル
        logging.info(f"{symbol}の会社プロファイルを更新します")
        results['profile'] = self.fetch_and_store_company_profile(symbol)
        
        # 従業員数データ
        logging.info(f"{symbol}の従業員数データを更新します")
        results['employee_count'] = self.fetch_and_store_employee_count(symbol)
        
        # 財務諸表データ
        # 年次データ
        logging.info(f"{symbol}の年次財務データを更新します")
        results['income_annual'] = self.fetch_and_store_income_statements(symbol, 'annual')
        results['balance_annual'] = self.fetch_and_store_balance_sheets(symbol, 'annual')
        results['cashflow_annual'] = self.fetch_and_store_cash_flows(symbol, 'annual')
        
        # 四半期データ
        logging.info(f"{symbol}の四半期財務データを更新します")
        results['income_quarter'] = self.fetch_and_store_income_statements(symbol, 'quarter')
        results['balance_quarter'] = self.fetch_and_store_balance_sheets(symbol, 'quarter')
        results['cashflow_quarter'] = self.fetch_and_store_cash_flows(symbol, 'quarter')
        
        # 株価データ
        logging.info(f"{symbol}の株価データを更新します")
        results['prices'] = self.fetch_and_store_historical_prices(symbol)
        
        # 株式数データ
        logging.info(f"{symbol}の株式数データを更新します")
        results['shares'] = self.fetch_and_store_shares(symbol)
        
        # ニュース
        logging.info(f"{symbol}のニュースデータを更新します")
        results['news'] = self.fetch_and_store_news(symbol, 20)
        
        # 一般的な通貨ペアを更新（銘柄がUSDの場合など）
        if symbol in ['USD', 'EUR', 'JPY', 'GBP', 'CAD', 'AUD', 'CHF']:
            common_pairs = ['USDJPY', 'EURUSD', 'GBPUSD', 'USDCAD', 'AUDUSD', 'USDCHF']
            logging.info(f"{symbol}に関連する為替データを更新します")
            forex_results = {}
            for pair in common_pairs:
                if symbol in pair:
                    forex_results[pair] = self.fetch_and_store_forex(pair)
                    
            results['forex'] = forex_results
        
        return results

    def migrate_db_tables(self):
        """データベーステーブルのマイグレーション・スキーマ確認を実行する"""
        import traceback
        self.logger.info("データベーステーブルのマイグレーションを開始します...")
        
        try:
            with self.db_engine.connect() as conn:
                # スキーマが存在することを確認
                conn.execute(text("CREATE SCHEMA IF NOT EXISTS fmp_data;"))
                
                # 1. company_newsテーブルの削除
                self.logger.info("company_newsテーブルを削除します...")
                try:
                    # company_newsテーブルが存在するか確認
                    news_exists = conn.execute(text("""
                        SELECT EXISTS (
                            SELECT FROM information_schema.tables 
                            WHERE table_schema = 'fmp_data' AND table_name = 'company_news'
                        );
                    """)).fetchone()[0]
                    
                    if news_exists:
                        conn.execute(text("DROP TABLE IF EXISTS fmp_data.company_news;"))
                        self.logger.info("company_newsテーブルを削除しました")
                    else:
                        self.logger.info("company_newsテーブルは存在しないため、削除は不要です")
                        
                except Exception as e:
                    self.logger.error(f"company_newsテーブルの削除中にエラーが発生しました: {e}")
                
                # 2. shares_floatテーブルの削除
                self.logger.info("shares_floatテーブルを削除します...")
                try:
                    # shares_floatテーブルが存在するか確認
                    shares_float_exists = conn.execute(text("""
                        SELECT EXISTS (
                            SELECT FROM information_schema.tables 
                            WHERE table_schema = 'fmp_data' AND table_name = 'shares_float'
                        );
                    """)).fetchone()[0]
                    
                    if shares_float_exists:
                        conn.execute(text("DROP TABLE IF EXISTS fmp_data.shares_float;"))
                        self.logger.info("shares_floatテーブルを削除しました")
                    else:
                        self.logger.info("shares_floatテーブルは存在しないため、削除は不要です")
                        
                except Exception as e:
                    self.logger.error(f"shares_floatテーブルの削除中にエラーが発生しました: {e}")
                
                # 3. employee_countテーブルをemployee_countsテーブルにリネーム
                self.logger.info("従業員数データテーブルのマイグレーションを実行中...")
                try:
                    # employee_countテーブルが存在するか確認
                    ec_exists = conn.execute(text("""
                        SELECT EXISTS (
                            SELECT FROM information_schema.tables 
                            WHERE table_schema = 'fmp_data' AND table_name = 'employee_count'
                        );
                    """)).fetchone()[0]
                    
                    # employee_countsテーブルが存在するか確認
                    ecs_exists = conn.execute(text("""
                        SELECT EXISTS (
                            SELECT FROM information_schema.tables 
                            WHERE table_schema = 'fmp_data' AND table_name = 'employee_counts'
                        );
                    """)).fetchone()[0]
                    
                    if ec_exists and not ecs_exists:
                        # employee_countsテーブルを作成
                        conn.execute(text("""
                            CREATE TABLE fmp_data.employee_counts (
                                symbol VARCHAR(20) NOT NULL,
                                date DATE NOT NULL,
                                employee_count INTEGER,
                                source TEXT,
                                PRIMARY KEY (symbol, date)
                            );
                        """))
                        
                        # employee_countからデータをコピー
                        conn.execute(text("""
                            INSERT INTO fmp_data.employee_counts (symbol, date, employee_count, source)
                            SELECT symbol, date, employee_count, source FROM fmp_data.employee_count
                            ON CONFLICT (symbol, date) DO NOTHING;
                        """))
                        
                        # 古いテーブルを削除
                        conn.execute(text("DROP TABLE IF EXISTS fmp_data.employee_count;"))
                        self.logger.info("employee_countテーブルからemployee_countsテーブルへの移行が完了しました")
                    elif not ec_exists and not ecs_exists:
                        # 両方のテーブルが存在しない場合は新規作成
                        conn.execute(text("""
                            CREATE TABLE fmp_data.employee_counts (
                                symbol VARCHAR(20) NOT NULL,
                                date DATE NOT NULL,
                                employee_count INTEGER,
                                source TEXT,
                                PRIMARY KEY (symbol, date)
                            );
                        """))
                        self.logger.info("employee_countsテーブルを新規作成しました")
                    elif not ec_exists and ecs_exists:
                        self.logger.info("employee_countsテーブルは既に存在するため、移行は不要です")
                    elif ec_exists and ecs_exists:
                        # 両方存在する場合はデータをマージして古いテーブルを削除
                        conn.execute(text("""
                            INSERT INTO fmp_data.employee_counts (symbol, date, employee_count, source)
                            SELECT symbol, date, employee_count, source FROM fmp_data.employee_count
                            ON CONFLICT (symbol, date) DO NOTHING;
                        """))
                        conn.execute(text("DROP TABLE IF EXISTS fmp_data.employee_count;"))
                        self.logger.info("employee_countからemployee_countsへのデータマージが完了しました")
                
                except Exception as e:
                    self.logger.error(f"従業員数テーブルのマイグレーション中にエラーが発生しました: {e}")
                
                # 4. newsテーブルが存在することを確認
                self._ensure_table_exists(conn, 'news', """
                    CREATE TABLE fmp_data.news (
                        symbol VARCHAR(20),
                        title TEXT NOT NULL,
                        published_date TIMESTAMP NOT NULL,
                        content TEXT,
                        url TEXT,
                        image TEXT,
                        site TEXT,
                        retrieved_at TIMESTAMP,
                        PRIMARY KEY (title, published_date)
                    );
                    CREATE INDEX IF NOT EXISTS idx_news_symbol ON fmp_data.news (symbol);
                    CREATE INDEX IF NOT EXISTS idx_news_published_date ON fmp_data.news (published_date);
                """)
                
                # sentiment_newsテーブルが存在することを確認
                self._ensure_table_exists(conn, 'sentiment_news', """
                    CREATE TABLE fmp_data.sentiment_news (
                        id SERIAL PRIMARY KEY,
                        symbol VARCHAR(20),
                        published_date TIMESTAMP NOT NULL,
                        title TEXT NOT NULL,
                        image TEXT,
                        site TEXT,
                        text TEXT,
                        url TEXT,
                        sentiment VARCHAR(20),
                        sentiment_score FLOAT,
                        retrieved_at TIMESTAMP,
                        CONSTRAINT sentiment_news_title_url_unique UNIQUE (title, url)
                    );
                    CREATE INDEX IF NOT EXISTS idx_sentiment_news_symbol ON fmp_data.sentiment_news (symbol);
                    CREATE INDEX IF NOT EXISTS idx_sentiment_news_published_date ON fmp_data.sentiment_news (published_date);
                """)
                
                # earnings_calendarテーブルが存在することを確認
                self._ensure_table_exists(conn, 'earnings_calendar', """
                    CREATE TABLE fmp_data.earnings_calendar (
                        symbol VARCHAR(20) NOT NULL,
                        report_date DATE NOT NULL,
                        eps_actual FLOAT,
                        eps_estimated FLOAT,
                        revenue_actual BIGINT,
                        revenue_estimated BIGINT,
                        last_updated DATE,
                        PRIMARY KEY (symbol, report_date)
                    );
                    CREATE INDEX IF NOT EXISTS idx_earnings_calendar_report_date ON fmp_data.earnings_calendar (report_date);
                """)
                
                # forexテーブルが存在することを確認
                self._ensure_table_exists(conn, 'forex', """
                    CREATE TABLE fmp_data.forex (
                        symbol VARCHAR(10) NOT NULL,
                        date DATE NOT NULL,
                        price FLOAT NOT NULL,
                        volume BIGINT,
                        PRIMARY KEY (symbol, date)
                    );
                    CREATE INDEX IF NOT EXISTS idx_forex_date ON fmp_data.forex (date);
                    CREATE INDEX IF NOT EXISTS idx_forex_symbol ON fmp_data.forex (symbol);
                """)
                
                # sharesテーブルが存在することを確認
                self._ensure_table_exists(conn, 'shares', """
                    CREATE TABLE fmp_data.shares (
                        symbol VARCHAR(20) NOT NULL,
                        date DATE NOT NULL,
                        free_float FLOAT,
                        float_shares BIGINT,
                        outstanding_shares BIGINT,
                        source TEXT,
                        PRIMARY KEY (symbol, date)
                    );
                    CREATE INDEX IF NOT EXISTS idx_shares_date ON fmp_data.shares (date);
                    CREATE INDEX IF NOT EXISTS idx_shares_symbol ON fmp_data.shares (symbol);
                """)
                
                # 5. sharesテーブルのパーティション化
                self._ensure_shares_partitioning(conn)
                
                self.logger.info("データベーステーブルのマイグレーションが完了しました")
                
        except Exception as e:
            self.logger.error(f"データベーステーブルのマイグレーション中にエラーが発生しました: {e}")
            self.logger.error(traceback.format_exc())
            return False
            
        return True

    def _ensure_table_exists(self, conn, table_name, create_table_sql):
        """
        指定したテーブルが存在することを確認し、存在しない場合は作成する
        
        パラメータ:
            conn: SQLAlchemy接続オブジェクト
            table_name (str): 確認するテーブル名
            create_table_sql (str): テーブル作成用SQL
        """
        try:
            # テーブルが存在するか確認
            result = conn.execute(text(f"""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_schema = 'fmp_data' AND table_name = '{table_name}'
                );
            """))
            
            if not result.fetchone()[0]:
                # テーブルが存在しない場合は作成
                self.logger.info(f"テーブル {table_name} を作成します...")
                conn.execute(text(create_table_sql))
                self.logger.info(f"テーブル {table_name} を作成しました")
            else:
                self.logger.info(f"テーブル {table_name} は既に存在します")
            
            # sharesテーブルの場合、パーティション機能を追加
            if table_name == 'shares':
                self._ensure_shares_partitioning(conn)
        except Exception as e:
            self.logger.error(f"テーブル {table_name} の確認・作成中にエラーが発生しました: {e}")
            self.logger.error(traceback.format_exc())

    def _ensure_shares_partitioning(self, conn):
        """sharesテーブルにパーティション機能を追加する"""
        try:
            # 既存テーブルがパーティション化されているか確認
            result = conn.execute(text("""
                SELECT EXISTS (
                    SELECT FROM pg_partitioned_table pt
                    JOIN pg_class pc ON pt.partrelid = pc.oid
                    JOIN pg_namespace pn ON pc.relnamespace = pn.oid
                    WHERE pc.relname = 'shares' AND pn.nspname = 'fmp_data'
                );
            """))
            
            is_partitioned = result.fetchone()[0]
            
            if not is_partitioned:
                self.logger.info("sharesテーブルをパーティション化するための準備を行います...")
                
                # 一時テーブルを作成
                conn.execute(text("""
                    CREATE TABLE fmp_data.shares_new (
                        symbol VARCHAR(20) NOT NULL,
                        date DATE NOT NULL,
                        free_float FLOAT,
                        float_shares BIGINT,
                        outstanding_shares BIGINT,
                        source TEXT,
                        PRIMARY KEY (symbol, date)
                    ) PARTITION BY RANGE (date);
                    
                    -- 年ごとのパーティションを作成
                    CREATE TABLE fmp_data.shares_p2020 PARTITION OF fmp_data.shares_new
                        FOR VALUES FROM ('2020-01-01') TO ('2021-01-01');
                    
                    CREATE TABLE fmp_data.shares_p2021 PARTITION OF fmp_data.shares_new
                        FOR VALUES FROM ('2021-01-01') TO ('2022-01-01');
                    
                    CREATE TABLE fmp_data.shares_p2022 PARTITION OF fmp_data.shares_new
                        FOR VALUES FROM ('2022-01-01') TO ('2023-01-01');
                    
                    CREATE TABLE fmp_data.shares_p2023 PARTITION OF fmp_data.shares_new
                        FOR VALUES FROM ('2023-01-01') TO ('2024-01-01');
                    
                    CREATE TABLE fmp_data.shares_p2024 PARTITION OF fmp_data.shares_new
                        FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');
                    
                    CREATE TABLE fmp_data.shares_p2025 PARTITION OF fmp_data.shares_new
                        FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');
                    
                    -- デフォルトパーティション
                    CREATE TABLE fmp_data.shares_pdefault PARTITION OF fmp_data.shares_new
                        DEFAULT;
                """))
                
                # データ移行
                conn.execute(text("""
                    INSERT INTO fmp_data.shares_new 
                    SELECT * FROM fmp_data.shares
                    ON CONFLICT (symbol, date) DO NOTHING;
                """))
                
                # 古いテーブルと新しいテーブルを入れ替え
                conn.execute(text("""
                    DROP TABLE fmp_data.shares;
                    ALTER TABLE fmp_data.shares_new RENAME TO shares;
                """))
                
                # インデックスの再作成
                conn.execute(text("""
                    CREATE INDEX IF NOT EXISTS idx_shares_date ON fmp_data.shares (date);
                    CREATE INDEX IF NOT EXISTS idx_shares_symbol ON fmp_data.shares (symbol);
                """))
                
                self.logger.info("sharesテーブルのパーティション化が完了しました")
            else:
                self.logger.info("sharesテーブルは既にパーティション化されています")
        except Exception as e:
            self.logger.error(f"sharesテーブルのパーティション化中にエラーが発生しました: {e}")
            self.logger.error(traceback.format_exc())

    def update_news_data(self):
        """ニュース関連データを更新"""
        # センチメントニュースの更新
        self.update_sentiment_news(pages=1)
    
    def update_symbol_status(self):
        """
        シンボルステータステーブルを更新
        
        現在上場中のシンボルとデータベースに存在するシンボルを収集し、
        それぞれのシンボルが上場中か廃止されているかを判定して
        symbol_statusテーブルを更新します。
        
        戻り値:
            bool: 更新成功ならTrue、失敗ならFalse
        """
        self.logger.info("シンボルステータステーブルの更新を開始します...")
        
        try:
            result = update_symbol_status()
            if result:
                self.logger.info("シンボルステータステーブルの更新が完了しました")
            else:
                self.logger.error("シンボルステータステーブルの更新に失敗しました")
            return result
        except Exception as e:
            self.logger.error(f"シンボルステータステーブル更新中にエラーが発生しました: {e}")
            self.logger.error(traceback.format_exc())
            return False

    def update_data(self, symbols, include_financials=True, include_daily_prices=True, 
                  include_news=False, include_earnings=True, include_company_profiles=True,
                  days_back=30, only_missing=False, force_update=False):
        """
        複数の銘柄の株価と財務データを更新する
        
        パラメータ:
            symbols (list): 更新する銘柄のリスト
            include_financials (bool): 財務データを更新するかどうか
            include_daily_prices (bool): 株価データを更新するかどうか
            include_news (bool): ニュースデータを更新するかどうか
            include_earnings (bool): 決算情報を更新するかどうか
            include_company_profiles (bool): 会社プロファイルを更新するかどうか
            days_back (int): 何日前までの株価データを取得するか
            only_missing (bool): 欠損データのみを更新するか
            force_update (bool): 強制的に更新するか
        
        戻り値:
            bool: 成功したかどうか
        """
        try:
            # 各データ型の更新処理
            if include_financials:
                self.update_financials_based_on_earnings(from_date=datetime.now().date() - timedelta(days=days_back), to_date=datetime.now().date())
            if include_daily_prices:
                self.fetch_and_store_historical_prices(symbol, days=days_back)
            if include_news:
                self.fetch_and_store_news(symbol, limit=50)
            if include_earnings:
                self.update_financials_based_on_earnings(from_date=datetime.now().date() - timedelta(days=days_back), to_date=datetime.now().date())
            if include_company_profiles:
                self.fetch_and_store_company_profile(symbol)
            
            # 処理時間とデータ使用量のサマリーをログに出力
            self._log_summary()
            
            return True
            
        except Exception as e:
            self.logger.error(f"データ更新中にエラーが発生しました: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            
            # エラーが発生した場合でもデータ使用量のサマリーをログに出力
            self._log_summary()
            
            return False
    
    def _log_summary(self):
        """処理時間とデータ使用量のサマリーをログに出力"""
        end_time = datetime.now()
        elapsed_time = end_time - self.start_time
        elapsed_seconds = elapsed_time.total_seconds()
        
        hours, remainder = divmod(int(elapsed_seconds), 3600)
        minutes, seconds = divmod(remainder, 60)
        
        self.logger.info("====== 処理サマリー ======")
        self.logger.info(f"開始時刻: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info(f"終了時刻: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info(f"処理時間: {hours}時間 {minutes}分 {seconds}秒")
        
        # FMP APIの使用量情報を取得して出力
        api_usage = self.api.get_api_usage_summary()
        self.logger.info(f"API通信回数: {api_usage['request_count']}回")
        self.logger.info(f"API通信データ量: {api_usage['total_data_size_formatted']}")
        self.logger.info(f"平均リクエストサイズ: {api_usage['average_request_size']}")
        self.logger.info("==========================")

    def _update_symbol_status(self, symbol, is_active=False):
        """シンボルのステータスを更新する（内部メソッド）"""
        try:
            with self.db_engine.connect() as conn:
                # is_activeをFalseに設定する場合はmanually_deactivatedもTrueに設定
                manually_deactivated = not is_active
                
                query = text("""
                    UPDATE fmp_data.symbol_status 
                    SET is_active = :is_active,
                        manually_deactivated = :manually_deactivated,
                        last_updated = NOW()
                    WHERE symbol = :symbol
                """)
                
                conn.execute(query, {
                    "symbol": symbol, 
                    "is_active": is_active,
                    "manually_deactivated": manually_deactivated
                })
                conn.commit()
                self.logger.info(f"{symbol}のステータスを更新しました: is_active={is_active}, manually_deactivated={manually_deactivated}")
        except Exception as e:
            self.logger.error(f"{symbol}のステータス更新中にエラーが発生: {e}")
            self.logger.error(traceback.format_exc())

# 実行例（スクリプトとして実行された場合のみ）
if __name__ == "__main__":
    # ロギングの設定
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # 更新対象の銘柄リスト
    symbols = ["AAPL", "MSFT", "GOOGL", "AMZN", "META"]
    
    # データマネージャの初期化
    data_manager = FMPDataManager()
    
    # 全銘柄のデータを更新
    results = data_manager.update_all_data_for_symbols(symbols)
    
    # 結果の表示
    for symbol, result in results.items():
        print(f"{symbol} 更新結果:")
        for data_type, success in result.items():
            status = "成功" if success else "失敗"
            print(f"  - {data_type}: {status}")